{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10628dc2",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5944b01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           im_name  label\n",
      "0      000231c.jpg      2\n",
      "1      0002574.jpg      5\n",
      "2      00027d5.jpg      7\n",
      "3      000304e.jpg      3\n",
      "4      00047fc.jpg      7\n",
      "...            ...    ...\n",
      "49995  d507197.jpg      5\n",
      "49996  d508429.jpg      1\n",
      "49997  d508cb7.jpg      9\n",
      "49998  d509167.jpg      3\n",
      "49999  d509c42.jpg      3\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "csv_path, csv_test_path = \"../../data/train.csv\", \"../../data/test.csv\"\n",
    "img_dir, img_dir_test = \"../../data/train_ims\", \"../../data/test_ims\"\n",
    "\n",
    "data_train = pd.read_csv(csv_path)\n",
    "print(data_train)\n",
    "data_test = pd.read_csv(csv_test_path)\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "for _, row in data_train.iterrows():\n",
    "    img_path = os.path.join(img_dir, row.iloc[0])\n",
    "    label = int(row.iloc[1])\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = np.array(img).flatten()\n",
    "    X_train.append(img)\n",
    "    y_train.append(label)\n",
    "\n",
    "for _, row in data_test.iterrows():\n",
    "    img_path = os.path.join(img_dir_test, row.iloc[0])\n",
    "    label = int(row.iloc[1])\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = np.array(img).flatten()\n",
    "    X_test.append(img)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819bad46",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39c4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dca99c",
   "metadata": {},
   "source": [
    "### Size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "941cba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training set (after flatten 3 * 32 * 32):  (50000, 3072)\n",
      "The shape of the testing set (after flatten 3 * 32 * 32):  (10000, 3072)\n",
      "The size of the label of the training set:  (50000,)\n",
      "The size of the label of the test set:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the training set (after flatten 3 * 32 * 32): \", X_train.shape)\n",
    "print(\"The shape of the testing set (after flatten 3 * 32 * 32): \", X_test.shape)\n",
    "print(\"The size of the label of the training set: \", y_train.shape)\n",
    "print(\"The size of the label of the test set: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f85c8",
   "metadata": {},
   "source": [
    "### Calculate the number of the labels of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b48f5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each label:\n",
      "       Count\n",
      "Label       \n",
      "0       5038\n",
      "1       5016\n",
      "2       5032\n",
      "3       4991\n",
      "4       4982\n",
      "5       4967\n",
      "6       4985\n",
      "7       4998\n",
      "8       5002\n",
      "9       4989\n"
     ]
    }
   ],
   "source": [
    "# Count the labels\n",
    "count_labels = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Create DataFrame\n",
    "label_counts_df = pd.DataFrame({\n",
    "    \"Label\": count_labels[0],\n",
    "    \"Count\": count_labels[1]\n",
    "}).set_index(\"Label\")\n",
    "\n",
    "# Print DataFrame\n",
    "print(\"Count of each label:\")\n",
    "print(label_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69e7e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Statistics for the training set:\n",
      "count    50000.00000\n",
      "mean         4.49258\n",
      "std          2.87539\n",
      "min          0.00000\n",
      "25%          2.00000\n",
      "50%          4.00000\n",
      "75%          7.00000\n",
      "max          9.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Other Statistics for the training set:\")\n",
    "print(pd.Series(y_train).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25260261",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48518988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (40000, 3072)\n",
      "Testing set shape: (10000, 3072)\n",
      "Training labels shape: (40000,)\n",
      "Testing labels shape: (10000,)\n",
      "Flattened training set shape: (40000, 3072)\n",
      "Flattened testing set shape: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED)\n",
    "# del X_train_aug, y_train_aug\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_val.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing labels shape:\", y_val.shape)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # Flatten the images\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)  # Flatten the images\n",
    "print(\"Flattened training set shape:\", X_train.shape)\n",
    "print(\"Flattened testing set shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07711f1d",
   "metadata": {},
   "source": [
    "### Extract original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ceacca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_statistics_extractor(image):\n",
    "    \"\"\"\n",
    "    Extract statistical features from the original image.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image, shape (H, W, C) or (H*W*C).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Statistical feature vector for the input image.\n",
    "    \"\"\"\n",
    "    # If the image is flattened, reshape it to (H, W, C)\n",
    "    if len(image.shape) == 1:\n",
    "        image = image.reshape(32, 32, 3)  # Adjust this based on your original image shape\n",
    "\n",
    "    resized_image = cv2.resize(image, (64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    return resized_image.flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58825fbc",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e3c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def SIFT_extractor(image, n_features=128):\n",
    "    \"\"\"\n",
    "    Extract SIFT features from a single image.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image, shape (H, W, C) or (H*W*C).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: SIFT descriptors for the input image. If no descriptors are found, returns an empty array.\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        image = np.array(image)\n",
    "\n",
    "    if len(image.shape) == 1:\n",
    "        image = image.reshape(32, 32, 3) \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    # If no descriptors are found, return an empty array\n",
    "    if descriptors is None:\n",
    "        return np.zeros((1, n_features)).flatten()\n",
    "\n",
    "    return np.mean(descriptors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e222f0",
   "metadata": {},
   "source": [
    "### HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35bf03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def HOG_extractor(image, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Extract HOG features from a single image.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image, shape (H, W, C) or (H*W*C).\n",
    "        target_size (tuple): Target size to resize the image before extracting HOG features.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Flattened HOG feature vector for the input image.\n",
    "    \"\"\"\n",
    "    # If the image is flattened, reshape it to (H, W, C)\n",
    "    if len(image.shape) == 1:\n",
    "        image = image.reshape(32, 32, 3)  # Adjust this based on your original image shape\n",
    "    \n",
    "    # Resize the image to the target size\n",
    "    resized_img = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # # Convert to grayscale (HOG works on single-channel images)\n",
    "    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_RGB2GRAY)\n",
    "    # print(\"Gray image shape:\", gray_img.shape)\n",
    "\n",
    "\n",
    "    # Split the image into three channels (R, G, B)\n",
    "    channels = cv2.split(resized_img)\n",
    "    # print(\"Channels shape:\", [channel.shape for channel in channels])\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_kwargs = {\n",
    "        \"_winSize\": (128, 128),\n",
    "        \"_blockSize\": (64, 64),\n",
    "        \"_blockStride\": (16, 16),\n",
    "        \"_cellSize\": (16, 16),\n",
    "        \"_nbins\": 10,\n",
    "        \"_derivAperture\": 1,\n",
    "        \"_winSigma\": -1,\n",
    "        \"_histogramNormType\": 0,\n",
    "        \"_L2HysThreshold\": 0.2,\n",
    "        \"_gammaCorrection\": True,\n",
    "        \"_nlevels\": 64,\n",
    "        \"_signedGradient\": True\n",
    "    }   \n",
    "\n",
    "    hog = cv2.HOGDescriptor(**hog_kwargs)\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_features = []\n",
    "    for channel in channels:\n",
    "        # Compute HOG features for the current channel\n",
    "        hog_feature = hog.compute(channel)\n",
    "        # print (\"HOG feature shape:\", hog_feature.shape)\n",
    "        hog_features.append(hog_feature.flatten())\n",
    "    \n",
    "    # gray_hog_feature = hog.compute(gray_img)\n",
    "    # hog_features.append(gray_hog_feature.flatten())\n",
    "    # print (\"Gray HOG feature shape:\", gray_hog_feature.shape)\n",
    "\n",
    "    # Flatten the HOG feature vector\n",
    "    return np.concatenate(hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711c201",
   "metadata": {},
   "source": [
    "### EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdf83933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EOG_extractor(image, target_size=(32, 32)):\n",
    "    \"\"\"\n",
    "    Extract Edge Orientation Gradient (EOG) features from a single image.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image, shape (H, W, C) or (H*W*C).\n",
    "        target_size (tuple): Target size to resize the image before extracting EOG features.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Flattened EOG feature vector for the input image.\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 1:\n",
    "        image = image.reshape(32, 32, 3)\n",
    "    # Resize the image to the target size\n",
    "    resized_img = cv2.resize(image, target_size, interpolation=cv2.INTER_CUBIC)\n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(gray_img, threshold1=100, threshold2=200)\n",
    "    # Compute gradients in x and y directions\n",
    "    grad_x = cv2.Sobel(edges, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(edges, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    # Compute gradient magnitude and orientation\n",
    "    magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    orientation = np.arctan2(grad_y, grad_x)\n",
    "    # Flatten the magnitude and orientation into a feature vector\n",
    "    eog_feature = np.concatenate([magnitude.flatten(), orientation.flatten()])\n",
    "\n",
    "    return eog_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a30f3",
   "metadata": {},
   "source": [
    "### LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936e7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "def LBP_extractor(image, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Extract Local Binary Pattern (LBP) features from a single image.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image, shape (H, W, C) or (H*W*C).\n",
    "        target_size (tuple): Target size to resize the image before extracting LBP features.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Flattened LBP feature vector for the input image.\n",
    "    \"\"\"\n",
    "    # If the image is flattened, reshape it to (H, W, C)\n",
    "    if len(image.shape) == 1:\n",
    "        image = image.reshape(32, 32, 3)  # Adjust this based on your original image shape\n",
    "    # Resize the image to the target size\n",
    "    resized_img = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    # Convert to grayscale\n",
    "    gray_img = rgb2gray(resized_img)\n",
    "    # Compute LBP features\n",
    "    lbp = local_binary_pattern(gray_img, P=8, R=1, method='uniform')\n",
    "    # Flatten the LBP feature vector\n",
    "    return lbp.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953e436",
   "metadata": {},
   "source": [
    "### ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b30f71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ORB_extractor(image, target_size=(64, 64), n_features=500, fixed_length=2000):\n",
    "    \"\"\"\n",
    "    Extract ORB features from a single image with fixed length.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image, shape (H, W, C) or (H*W*C).\n",
    "        target_size (tuple): Target size to resize the image before extracting ORB features.\n",
    "        n_features (int): Maximum number of features to retain.\n",
    "        fixed_length (int): Fixed length for the ORB feature vector.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Flattened ORB descriptors with fixed length. If no descriptors are found, returns a zero vector.\n",
    "    \"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=n_features)\n",
    "\n",
    "    # If the image is flattened, reshape it to (H, W, C)\n",
    "    if len(image.shape) == 1:\n",
    "        image = image.reshape(32, 32, 3)\n",
    "\n",
    "    # Resize the image to the target size\n",
    "    resized_img = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_RGB2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray_img, None)\n",
    "    # If no descriptors are found, return a zero vector\n",
    "    if descriptors is None:\n",
    "        descriptors = np.zeros((1, 32), dtype=np.uint8)\n",
    "    # Flatten the descriptors\n",
    "    descriptors = descriptors.flatten()\n",
    "\n",
    "    # Ensure the feature vector has a fixed length\n",
    "    if len(descriptors) < fixed_length:\n",
    "        descriptors = np.pad(descriptors, (0, fixed_length - len(descriptors)), mode='constant')\n",
    "    elif len(descriptors) > fixed_length:\n",
    "        descriptors = descriptors[:fixed_length]\n",
    "\n",
    "    return descriptors.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0e7fd",
   "metadata": {},
   "source": [
    "### HIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "021e6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HIST_extractor(image, target_size=(64, 64), bins=(8, 8, 8)):\n",
    "    \"\"\"\n",
    "    Extract color histogram (HIST) features from a single image.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image, shape (H, W, C) or (H*W*C).\n",
    "        target_size (tuple): Target size to resize the image before extracting HIST features.\n",
    "        bins (tuple): Number of bins for each color channel (e.g., (8, 8, 8)).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Flattened HIST feature vector for the input image.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(image.shape) == 1:\n",
    "        image = image.reshape(32, 32, 3)\n",
    "\n",
    "    # Resize the image to the target size\n",
    "    resized_img = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    # Compute the color histogram for each channel (B, G, R)\n",
    "    hist = cv2.calcHist([resized_img], [0, 1, 2], None, bins, [0, 256, 0, 256, 0, 256])\n",
    "    # Normalize the histogram\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316ea8c",
   "metadata": {},
   "source": [
    "### Combine the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e93fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_flag = False\n",
    "\n",
    "def combined_feature_extractor(image):\n",
    "    \"\"\"\n",
    "    Extract combined features (HOG, EOG, LBP, ORB, HIST, SIFT) from a single input image.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image, shape (H, W, C) or (H*W*C).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Combined feature vector for the input image.\n",
    "    \"\"\"\n",
    "    # # Extract features\n",
    "    # static_features = image_statistics_extractor(image)  # Original image statistics\n",
    "    # sift_features = SIFT_extractor(image)  # SIFT features\n",
    "    # hog_features = HOG_extractor(image)   # HOG features\n",
    "    # eog_features = EOG_extractor(image)   # EOG features\n",
    "    # # lbp_features = LBP_extractor(image)   # LBP features\n",
    "    # orb_features = ORB_extractor(image)   # ORB features\n",
    "    # hist_features = HIST_extractor(image) # HIST features\n",
    "\n",
    "    global print_flag\n",
    "\n",
    "    # static_features = np.array(image_statistics_extractor(image), dtype=np.float32)\n",
    "    sift_features = np.array(SIFT_extractor(image), dtype=np.float32)\n",
    "    hog_features = np.array(HOG_extractor(image), dtype=np.float32)\n",
    "    eog_features = np.array(EOG_extractor(image), dtype=np.float32)\n",
    "    # lbp_features = np.array(LBP_extractor(image))\n",
    "    orb_features = np.array(ORB_extractor(image), dtype=np.float32)\n",
    "    hist_features = np.array(HIST_extractor(image), dtype=np.float32)\n",
    "\n",
    "    # Combine features into a single vector\n",
    "    combined_features = np.concatenate((\n",
    "        # static_features,\n",
    "        sift_features,\n",
    "        hog_features,\n",
    "        eog_features,\n",
    "        # lbp_features,\n",
    "        orb_features,\n",
    "        hist_features,\n",
    "    ))\n",
    "\n",
    "    # Print feature shapes for debugging\n",
    "    if print_flag == False:\n",
    "        # print(\"Static features shape:\", static_features.shape)\n",
    "        print(\"HOG features shape:\", hog_features.shape)\n",
    "        print(\"EOG features shape:\", eog_features.shape)\n",
    "        print(\"ORB features shape:\", orb_features.shape)\n",
    "        print(\"HIST features shape:\", hist_features.shape)\n",
    "        print(\"SIFT features shape:\", sift_features.shape)\n",
    "        print_flag = True\n",
    "    \n",
    "    # del static_features\n",
    "    del sift_features\n",
    "    del hog_features\n",
    "    del eog_features\n",
    "    # del lbp_features\n",
    "    del orb_features\n",
    "    del hist_features\n",
    "    \n",
    "    # RECORD MANUALLY THE SHAPE OF EACH FEATURE\n",
    "    # Static features shape: (12288,)\n",
    "    # HOG features shape: (8100,)\n",
    "    # EOG features shape: (8192,)\n",
    "    # ORB features shape: (8000,)\n",
    "    # HIST features shape: (512,)\n",
    "    # SIFT features shape: (128,)\n",
    "\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81bd64",
   "metadata": {},
   "source": [
    "### Convert training set with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe655de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from training and validation sets\n",
    "# X_train_features = [combined_feature_extractor(img) for img in tqdm(X_train, desc=\"Extracting features for X_train\", total=len(X_train))]\n",
    "# X_val_features = [combined_feature_extractor(img) for img in tqdm(X_val, desc=\"Extracting features for X_val\", total=len(X_val))]\n",
    "X_train_features = list(X_train)\n",
    "X_val_features = list(X_val)\n",
    "del X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed38cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_featured shape: (40000, 3072)\n",
      "X_val_featured shape: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "X_train_featured = np.array(X_train_features, dtype=np.float32)\n",
    "X_val_featured = np.array(X_val_features, dtype=np.float32)\n",
    "del X_train_features, X_val_features\n",
    "\n",
    "print(\"X_train_featured shape:\", X_train_featured.shape)\n",
    "print(\"X_val_featured shape:\", X_val_featured.shape)\n",
    "\n",
    "# Save the features to numpy arrays\n",
    "# np_path = \"../data/nparrays\"\n",
    "# os.makedirs(np_path, exist_ok=True)\n",
    "# np.save(os.path.join(np_path, \"X_train_features5.npy\"), X_train_featured)\n",
    "# np.save(os.path.join(np_path, \"X_val_features5.npy\"), X_val_featured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e03ea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_featured shape: (40000, 3072)\n",
      "X_val_featured shape: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(X_train_features)):\n",
    "#     print(f\"Image {i} has shape {X_train_features[i].shape}\")\n",
    "# for i in range(len(X_val_features)):\n",
    "#     print(f\"Image {i} has shape {X_val_features[i].shape}\")\n",
    "\n",
    "# del X_train_features\n",
    "# del X_val_features\n",
    "# del X_train\n",
    "# del X_val\n",
    "\n",
    "print(\"X_train_featured shape:\", X_train_featured.shape)\n",
    "print(\"X_val_featured shape:\", X_val_featured.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d25d5",
   "metadata": {},
   "source": [
    "### SVM + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99bed4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Accelerate the code using Intel's scikit-learn optimizations\n",
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ffaf644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\Lib\\site-packages\\sklearnex\\decomposition\\pca.py:377: UserWarning: Sklearnex always uses `covariance_eigh` solver instead of `full` when `svd_solver` parameter is set to `auto` for performance purposes.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy: 0.4978\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54      1011\n",
      "           1       0.58      0.60      0.59      1051\n",
      "           2       0.38      0.38      0.38       985\n",
      "           3       0.35      0.33      0.34       983\n",
      "           4       0.41      0.41      0.41       968\n",
      "           5       0.44      0.39      0.41       975\n",
      "           6       0.49      0.59      0.54      1022\n",
      "           7       0.59      0.55      0.57       987\n",
      "           8       0.60      0.62      0.61       996\n",
      "           9       0.58      0.54      0.56      1022\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.50      0.50      0.49     10000\n",
      "weighted avg       0.50      0.50      0.50     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_model = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    PCA(n_components=0.75, random_state=SEED), \n",
    "    SVC(C=8, kernel='rbf', gamma='scale',random_state=SEED))\n",
    "\n",
    "svm_model.fit(X_train_featured, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_val_featured)\n",
    "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
    "print(f\"SVM Validation Accuracy: {accuracy_svm:.4f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# # Confusion Matrix\n",
    "# cm = confusion_matrix(y_val, y_pred_svm)\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val)) \n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_val, y_pred_svm)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e288cc",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41c5a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\Lib\\site-packages\\sklearnex\\decomposition\\pca.py:377: UserWarning: Sklearnex always uses `covariance_eigh` solver instead of `full` when `svd_solver` parameter is set to `auto` for performance purposes.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Validation Accuracy: 0.4029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.57      0.48      1011\n",
      "           1       0.55      0.40      0.47      1051\n",
      "           2       0.28      0.38      0.32       985\n",
      "           3       0.31      0.21      0.25       983\n",
      "           4       0.28      0.38      0.32       968\n",
      "           5       0.42      0.26      0.32       975\n",
      "           6       0.36      0.51      0.42      1022\n",
      "           7       0.57      0.36      0.44       987\n",
      "           8       0.49      0.57      0.53       996\n",
      "           9       0.59      0.36      0.45      1022\n",
      "\n",
      "    accuracy                           0.40     10000\n",
      "   macro avg       0.43      0.40      0.40     10000\n",
      "weighted avg       0.43      0.40      0.40     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_model = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    PCA(n_components=0.75, random_state=SEED), \n",
    "    KNeighborsClassifier(n_neighbors=10))\n",
    "\n",
    "knn_model.fit(X_train_featured, y_train)\n",
    "\n",
    "y_pred_svm = knn_model.predict(X_val_featured)\n",
    "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
    "print(f\"KNN Validation Accuracy: {accuracy_svm:.4f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# # Confusion Matrix\n",
    "# cm = confusion_matrix(y_val, y_pred_svm)\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val)) \n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_val, y_pred_svm)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd58be3",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f74cfb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\Lib\\site-packages\\sklearnex\\decomposition\\pca.py:377: UserWarning: Sklearnex always uses `covariance_eigh` solver instead of `full` when `svd_solver` parameter is set to `auto` for performance purposes.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Validation Accuracy: 0.4573\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.52      0.52      1011\n",
      "           1       0.50      0.56      0.53      1051\n",
      "           2       0.40      0.34      0.37       985\n",
      "           3       0.32      0.29      0.30       983\n",
      "           4       0.41      0.38      0.39       968\n",
      "           5       0.38      0.35      0.37       975\n",
      "           6       0.45      0.51      0.48      1022\n",
      "           7       0.53      0.47      0.50       987\n",
      "           8       0.53      0.62      0.57       996\n",
      "           9       0.48      0.52      0.50      1022\n",
      "\n",
      "    accuracy                           0.46     10000\n",
      "   macro avg       0.45      0.46      0.45     10000\n",
      "weighted avg       0.45      0.46      0.45     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RF_model = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    PCA(n_components=0.75, random_state=SEED), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=SEED))\n",
    "\n",
    "RF_model.fit(X_train_featured, y_train)\n",
    "\n",
    "y_pred_svm = RF_model.predict(X_val_featured)\n",
    "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
    "print(f\"RF Validation Accuracy: {accuracy_svm:.4f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# # Confusion Matrix\n",
    "# cm = confusion_matrix(y_val, y_pred_svm)\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val)) \n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_val, y_pred_svm)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_svm))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
